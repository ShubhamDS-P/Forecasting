# -*- coding: utf-8 -*-
"""Forecasting of Airline's Passengers.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AABu0w2sDPv4l4oh9mfH0bwqbTxV7XuV
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.holtwinters import SimpleExpSmoothing # SES
from statsmodels.tsa.holtwinters import Holt # Holts Exponential Smoothing
from statsmodels.tsa.holtwinters import ExponentialSmoothing # 
import statsmodels.graphics.tsaplots as tsa_plots
import statsmodels.tsa.statespace as tm_models
from datetime import datetime,time

from google.colab import files
Airlines = files.upload()

airlines = pd.read_excel("Airlines+Data.xlsx")

print(airlines)

airlines.columns

# Converting the normal index of airlines dataset to times stamp
airlines.index = pd.to_datetime(airlines.Month,format="%b-%y")
print(airlines)

airlines.Passengers.plot()

airlines.head(12)

# Creating the Date column to store the actual date format for the given month
airlines['Date'] = pd.to_datetime(airlines.Month, format = "%b-%y")
print(airlines)

# Extracting Day, Weekday name, month name, year from the date column using Date functions from pandas
airlines["month"] = airlines.Date.dt.strftime("%b")
airlines

airlines["year"] = airlines.Date.dt.strftime("%y")
airlines

# Heat map visulization
heatmap_year_month = pd.pivot_table(data=airlines, values="Passengers",index = "year", columns= "month",aggfunc = "mean", fill_value=0)
sns.heatmap(heatmap_year_month,annot=True,fmt="g")

# Boxplot for all the data
sns.boxplot(x="month",y="Passengers",data=airlines)

sns.boxplot(x="year",y = "Passengers",data=airlines)

# Line plot for plane passengers based on year and for each month
sns.lineplot(x="year",y="Passengers",hue = "month",data=airlines)

# Lets see the moving average for the time series to understand better about the trend character in airlines
airlines.Passengers.plot(label="org")

for i in range(2,24,6):
  airlines["Passengers"].rolling(i).mean().plot(label=str(i))
plt.legend(loc=3)

# Time series decomposition plot
decompose_ts_add = seasonal_decompose(airlines.Passengers,model="additive")
decompose_ts_add.plot()

# Decomposition plot for multiplicative seasonality
decompose_ts_mul = seasonal_decompose(airlines.Passengers,model = "multiplicative")
decompose_ts_mul.plot()

# ACF plots and PACF plots on the original data sets
# ACF plot
tsa_plots.plot_acf(airlines.Passengers,lags=10)
# From ACF we can decide that the range of the q value will be from 1 to 7

# PACF plot
tsa_plots.plot_pacf(airlines.Passengers)
# From PACF plot we can say that the values 1,9 and 11 will be significant for the q value.

len(airlines)

# Let's split the given data into train and test data where the last 12 months will be test data while the remaining will be train data.
train = airlines.head(84)
test = airlines.tail(12)
test,train

test

# Crating a function to calculate the MAPE of the test data
# MAPE Stands for Mean Absolute Percentage Error
def MAPE(pred,org):
  temp = np.abs((pred-org))*100/org
  return np.mean(temp)

# Now let's build various models for the prepared train and test data
# Simple Exponential Method
ses_model = SimpleExpSmoothing(train["Passengers"]).fit()
pred_ses = ses_model.predict(start = test.index[0],end = test.index[-1])
mape_ses = MAPE(pred_ses,test.Passengers)
print(MAPE(pred_ses,test.Passengers))

# Holt method
hw_model = Holt(train["Passengers"]).fit()
pred_hw = hw_model.predict(start = test.index[0],end = test.index[-1])
mape_hw = MAPE(pred_hw,test.Passengers)
print(MAPE(pred_hw,test.Passengers))

# Holts winter exponential smoothing with additive seasonality and additive trend
hwe_model_add_add = ExponentialSmoothing(train["Passengers"],seasonal = "add",trend = "add", seasonal_periods = 12, damped = True).fit()
pred_hwe_add_add = hwe_model_add_add.predict(start = test.index[0],end = test.index[-1])
mape_hwe_add_add = MAPE(pred_hwe_add_add,test.Passengers)
print(MAPE(pred_hwe_add_add,test.Passengers))

# Holts winter exponential smoothing with miltiplicative seasonality and additive trend
hwe_model_mul_add = ExponentialSmoothing(train["Passengers"],seasonal="mul",trend="add",seasonal_periods = 12).fit()
pred_hwe_mul_add = hwe_model_mul_add.predict(start = test.index[0],end = test.index[-1])
mape_hwe_mul_add = MAPE(pred_hwe_mul_add,test.Passengers)
MAPE(pred_hwe_mul_add,test.Passengers)

pip install pmdarima

# Let's use auto_arima
import pmdarima as pm
from pmdarima import model_selection

auto_arima_model = pm.auto_arima(train["Passengers"],start_p= 0,start_q = 0,max_p = 10,max_q = 10,m=12,start_P = 0,seasonal = True,d=1,D=1,trace = True,error_action= "ignore",supress_warnigs=True,stepwise=False)

# To look at the model's some of the important aspects and points we will take the summary of the model.
#where we will look at the SARIMAX(1,1,1)x(0,1,1,12), AIC, BIC,etc.
auto_arima_model.summary()

# Now to get the fitted values of the train data set we will use the function "predict_in_sample()"
auto_arima_model.predict_in_sample()

# For getting the predictions for the future value we will use predict() function
auto_arima_pred_test = pd.Series(auto_arima_model.predict(n_periods=12))
auto_arima_pred_test

test

# Let's add the index values of the Test Data set to predictions of Auto Arima
auto_arima_pred_test.index = test.index
mape_auto_arima_model = MAPE(auto_arima_pred_test,test.Passengers)
MAPE(pred_test,test.Passengers)

# Now Let's use Sarimax from statsmodels
# As we don't have automatic function in identifying the best p,d,q combination, iterate over multiple combinations and return the best combination.
# For sarimax we require p,d,q and P,D,Q
from itertools import product
combinations_l = list(product(range(1,7),range(2),(1,9)))
combinations_u = list(product(range(1,7),range(2),(1,9)))
print(combinations_l)
len(combinations_l)

print(combinations_u)
len(combinations_u)

import warnings
warnings.filterwarnings("ignore")

# Even with the least number of required combinations it takes too long to complete the model's execution
# Hence I will skip the execution of the further code where we get the predictions and find out its MAPE.
# But up to the ARIMA model I have done all the requiered procedures.

# m = 12
# results_sarima = []
# best_aic = float("inf")

# for i in combinations_l:
#   for j in combinations_u:
#     try:
#       model_sarima = sm.tsa.statespace.SARIMAX(train["Passengers"],order = i,seasonal_order = j+(m,)).fit(disp=-1)
#     except:
#       continue
#     aic = model_sarima.aic
#     if aic < best_aic:
#       best_model = model_sarima
#       best_aic = aic
#       best_l = i
#       best_u = j
#     results_sarima.append([i,j,model_sarima.aic])

# dictionary = dict()
# m = 12
# for i in combinations_l:
#   for j in combinations_u:
#     try:
#       model = sm.tsa.statespace.SARIMAX(train["Passengers"],order = i, seasonal_order = j+(m,))
#       model_sarima = model.fit()
#       print('ARIMA{}x{}12 - AIC:{}'.format(i,j,model_sarima.aic))
#       dictionary.update({(i,j):model_sarima.aic})
#     except:
#       continue

dictionary

# result_sarima_table = pd.DataFrame(results_sarima)
# result_sarima_table.columns = ["parameters_1","parameters_j","aic"]
# result_sarima_table = result_sarima_table.sort_values(by="aic",ascending=True).reset_index(drop=True)

best_fit_model = sm.tsa.statespace.SARIMAX(train["Passengers"],order = (1,1,1),seasonal_order = (1,1,1,12)).fit(disp=-1) # disp = -1 helps to neglect the errors.
best_fit_model.summary()

best_fit_model.aic

sarima_pred = best_fit_model.predict(start = test.index[0],end = test.index[-1])
airlines["sarima_pred"] = sarima_pred
sarima_pred

mape_sarima = MAPE(sarima_pred,test.Passengers)
mape_sarima

MAPE_Table ={"MODLE" : pd.Series(["ses_model","hw_model","hwe_model_add_add","hwe_model_mul_mul","auto_arima_model","sarima_model"]),
             "MAPE": pd.Series([mape_ses,mape_hw,mape_hwe_add_add,mape_hwe_mul_add,mape_auto_arima_model,mape_sarima])}
MAPE_Table

Best_model_comparison_table = pd.DataFrame(MAPE_Table)
Best_model_comparison_table

# # So by taking a look at the table we can say that the "Holt's Winter Exponential Model with Additive Seasonality and Additive Trend" is giving the least MAPE 
# value i.e. Error. So we will use this model for the prediction and forecasting of the similar data in future.